"""AI Provider configuration and unified interface."""
from typing import Optional, Literal, List, Dict, Any
from openai import OpenAI
import anthropic
import json


# ÊîØÊåÅÁöÑAIÊèê‰æõÂïÜÁ±ªÂûã
AIProviderType = Literal[
    "openai",           # OpenAI GPT
    "anthropic",        # Anthropic Claude
    "google",           # Google Gemini
    "deepseek",         # DeepSeek
    "qwen",             # ÈòøÈáå‰∫ëÈÄö‰πâÂçÉÈóÆ
    "glm",              # Êô∫Ë∞±AI (GLM)
    "moonshot",         # Êúà‰πãÊöóÈù¢ Kimi
    "ernie",            # ÁôæÂ∫¶ÊñáÂøÉ‰∏ÄË®Ä
    "minimax",          # MiniMax
    "doubao",           # Â≠óËäÇË±ÜÂåÖ
    "ollama",           # Ollama Êú¨Âú∞Ê®°Âûã
    "mock"              # Mock Ê®°ÂºèÔºàÊµãËØïÁî®Ôºâ
]


class BaseAIClient:
    """Base AI client interface."""
    
    def __init__(self, model: str, **kwargs):
        self.model = model
        self.kwargs = kwargs
    
    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.3,
        **extra_params
    ) -> str:
        """
        Send chat completion request.
        
        Args:
            messages: List of message dicts with 'role' and 'content'
            temperature: Sampling temperature
            extra_params: Additional provider-specific parameters
            
        Returns:
            Response text content
        """
        raise NotImplementedError


class OpenAIClient(BaseAIClient):
    """OpenAI GPT client."""
    
    def __init__(self, api_key: str, model: str, base_url: Optional[str] = None):
        super().__init__(model)
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
    
    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.3,
        **extra_params
    ) -> str:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            response_format={"type": "json_object"} if extra_params.get("json_mode") else None,
            **{k: v for k, v in extra_params.items() if k != "json_mode"}
        )
        return response.choices[0].message.content


class AnthropicClient(BaseAIClient):
    """Anthropic Claude client."""
    
    def __init__(self, api_key: str, model: str, base_url: Optional[str] = None):
        super().__init__(model)
        kwargs = {"api_key": api_key}
        if base_url:
            kwargs["base_url"] = base_url
        self.client = anthropic.Anthropic(**kwargs)
    
    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.3,
        **extra_params
    ) -> str:
        # Anthropic ÁöÑ messages Ê†ºÂºèÁ®çÊúâ‰∏çÂêåÔºåÈúÄË¶ÅÂàÜÁ¶ª system Ê∂àÊÅØ
        system_msg = None
        user_messages = []
        
        for msg in messages:
            if msg["role"] == "system":
                system_msg = msg["content"]
            else:
                user_messages.append(msg)
        
        # Â¶ÇÊûúËØ∑Ê±Ç JSON Ê®°ÂºèÔºåÂú® system prompt ‰∏≠Ê∑ªÂä†Ë¶ÅÊ±Ç
        if extra_params.get("json_mode"):
            json_instruction = "\n\nÈáçË¶ÅÔºöËØ∑Á°Æ‰øùËøîÂõûÁöÑÂÜÖÂÆπÊòØÊúâÊïàÁöÑ JSON Ê†ºÂºèÔºå‰∏çË¶ÅÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñÁöÑÊñáÊú¨ÊàñËØ¥Êòé„ÄÇ"
            if system_msg:
                system_msg = system_msg + json_instruction
            else:
                system_msg = json_instruction.strip()
        
        kwargs = {
            "model": self.model,
            "messages": user_messages,
            "temperature": temperature,
            "max_tokens": extra_params.get("max_tokens", 4096)
        }
        
        # ËøáÊª§Êéâ json_mode ÂèÇÊï∞
        kwargs = {k: v for k, v in kwargs.items() if k != "json_mode"}
        
        if system_msg:
            kwargs["system"] = system_msg
        
        response = self.client.messages.create(**kwargs)
        return response.content[0].text


class GoogleGeminiClient(BaseAIClient):
    """Google Gemini client (via OpenAI-compatible API)."""
    
    def __init__(self, api_key: str, model: str, base_url: Optional[str] = None):
        super().__init__(model)
        # Google Gemini ÂèØ‰ª•ÈÄöËøá OpenAI ÂÖºÂÆπÊé•Âè£ËÆøÈóÆ
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url or "https://generativelanguage.googleapis.com/v1beta/openai/"
        )
    
    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.3,
        **extra_params
    ) -> str:
        # Â§ÑÁêÜ json_mode ÂèÇÊï∞
        params = {k: v for k, v in extra_params.items() if k != "json_mode"}
        if extra_params.get("json_mode"):
            params["response_format"] = {"type": "json_object"}
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            **params
        )
        return response.choices[0].message.content


class OpenAICompatibleClient(BaseAIClient):
    """
    Generic OpenAI-compatible client for providers like:
    - DeepSeek
    - ÈÄö‰πâÂçÉÈóÆ (Qwen)
    - Êô∫Ë∞±AI (GLM)
    - Moonshot (Kimi)
    - ÊñáÂøÉ‰∏ÄË®Ä (ERNIE)
    - MiniMax
    - Ë±ÜÂåÖ (Doubao)
    - Ollama
    """
    
    def __init__(self, api_key: str, model: str, base_url: str):
        super().__init__(model)
        # ËßÑËåÉÂåñ base_urlÔºöÁßªÈô§Êú´Â∞æÊñúÊù†ÔºàÈô§ÈùûÊòØ Google ÁöÑÁâπÊÆäÊÉÖÂÜµÔºâ
        normalized_base_url = base_url.rstrip('/') if not base_url.endswith('/openai/') else base_url
        
        # ÁâπÊÆäÂ§ÑÁêÜÔºöOllama ÈúÄË¶Å /v1 ÂêéÁºÄ
        # Â¶ÇÊûú base_url ÊòØ localhost:11434 ‰∏îÊ≤°Êúâ /v1ÔºåËá™Âä®Ê∑ªÂä†
        if ':11434' in normalized_base_url and not normalized_base_url.endswith('/v1'):
            normalized_base_url = normalized_base_url + '/v1'
            print(f"‚ö†Ô∏è  [AIÂÆ¢Êà∑Á´Ø] Ê£ÄÊµãÂà∞ Ollama base_urlÔºåÂ∑≤Ëá™Âä®Ê∑ªÂä† /v1 ÂêéÁºÄ")
        
        # È™åËØÅ base_url Ê†ºÂºè
        if not normalized_base_url.startswith(('http://', 'https://')):
            raise ValueError(f"Invalid base_url format: {base_url}. Must start with http:// or https://")
        
        print(f"üîó [AIÂÆ¢Êà∑Á´Ø] ÂàùÂßãÂåñ OpenAI ÂÖºÂÆπÂÆ¢Êà∑Á´Ø")
        print(f"   Model: {model}")
        print(f"   Base URL: {normalized_base_url}")
        
        self.client = OpenAI(
            api_key=api_key,
            base_url=normalized_base_url
        )
    
    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.3,
        **extra_params
    ) -> str:
        # Â§ÑÁêÜ json_mode ÂèÇÊï∞
        params = {k: v for k, v in extra_params.items() if k != "json_mode"}
        if extra_params.get("json_mode"):
            params["response_format"] = {"type": "json_object"}
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                **params
            )
            return response.choices[0].message.content
        except Exception as e:
            # Êèê‰æõÊõ¥ËØ¶ÁªÜÁöÑÈîôËØØ‰ø°ÊÅØ
            error_msg = str(e)
            error_type = type(e).__name__
            
            # Ëé∑ÂèñÂÆûÈôÖÁöÑ base_urlÔºà‰ªéÂÆ¢Êà∑Á´ØÂØπË±°Ôºâ
            actual_base_url = getattr(self.client, 'base_url', 'unknown')
            
            if "404" in error_msg or "not found" in error_msg.lower() or error_type == "NotFoundError":
                raise ValueError(
                    f"API endpoint not found (404). "
                    f"Please check your base_url configuration. "
                    f"Current base_url: {actual_base_url}, "
                    f"Model: {self.model}. "
                    f"This usually means:\n"
                    f"  1. The base_url is incorrect or incomplete\n"
                    f"  2. The API endpoint path is wrong\n"
                    f"  3. The service is not available at the specified URL\n"
                    f"Original error: {error_msg}"
                ) from e
            raise


class MockClient(BaseAIClient):
    """Mock client for testing."""
    
    def __init__(self):
        super().__init__("mock")
    
    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.3,
        **extra_params
    ) -> str:
        # ËøîÂõû‰∏Ä‰∏™ÁÆÄÂçïÁöÑmockÂìçÂ∫î
        return json.dumps({
            "triplets": [
                {
                    "subject": "Á§∫‰æã‰∏ª‰Ωì",
                    "predicate": "relates_to",
                    "object": "Á§∫‰æãÂÆ¢‰Ωì",
                    "confidence": 0.5,
                    "language": "zh"
                }
            ]
        })


class AIProviderFactory:
    """Factory for creating AI clients."""
    
    # ÈªòËÆ§ÁöÑ base_url ÈÖçÁΩÆ
    # Ê≥®ÊÑèÔºöbase_url ‰∏çÂ∫î‰ª•ÊñúÊù†ÁªìÂ∞æÔºàÈô§‰∫Ü Google ÁöÑÁâπÊÆäÊÉÖÂÜµÔºâ
    DEFAULT_BASE_URLS = {
        "openai": None,  # ‰ΩøÁî®ÈªòËÆ§
        "anthropic": None,
        "google": "https://generativelanguage.googleapis.com/v1beta/openai/",  # Google ÈúÄË¶ÅÊú´Â∞æÊñúÊù†
        "deepseek": "https://api.deepseek.com/v1",
        "qwen": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "glm": "https://open.bigmodel.cn/api/paas/v4",
        "moonshot": "https://api.moonshot.cn/v1",
        "ernie": "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop",  # ÊñáÂøÉ‰∏ÄË®Ä API
        "minimax": "https://api.minimax.chat/v1",
        "doubao": "https://ark.cn-beijing.volces.com/api/v3",
        "ollama": "http://localhost:11434/v1"
    }
    
    # ÈªòËÆ§Ê®°ÂûãÈÖçÁΩÆ
    DEFAULT_MODELS = {
        "openai": "gpt-4o-mini",
        "anthropic": "claude-3-5-sonnet-20241022",
        "google": "gemini-2.0-flash-exp",
        "deepseek": "deepseek-chat",
        "qwen": "qwen-plus",
        "glm": "glm-4-flash",
        "moonshot": "moonshot-v1-8k",
        "ernie": "ernie-4.0-8k-latest",
        "minimax": "abab6.5s-chat",
        "doubao": "doubao-pro-4k",
        "ollama": "llama3",
        "mock": "mock"
    }
    
    @classmethod
    def create_client(
        cls,
        provider: AIProviderType,
        api_key: Optional[str] = None,
        model: Optional[str] = None,
        base_url: Optional[str] = None
    ) -> BaseAIClient:
        """
        Create AI client based on provider type.
        
        Args:
            provider: AI provider type
            api_key: API key (not needed for mock/ollama)
            model: Model name (use default if not provided)
            base_url: Custom base URL (use default if not provided)
            
        Returns:
            AI client instance
            
        Raises:
            ValueError: If provider is not supported or missing required config
        """
        # ‰ΩøÁî®ÈªòËÆ§Ê®°ÂûãÂíåbase_urlÔºàÂ¶ÇÊûúÊú™Êèê‰æõÔºâ
        model = model or cls.DEFAULT_MODELS.get(provider)
        base_url = base_url or cls.DEFAULT_BASE_URLS.get(provider)
        
        if provider == "mock":
            return MockClient()
        
        if provider == "openai":
            if not api_key:
                raise ValueError("OpenAI API key is required")
            return OpenAIClient(api_key, model, base_url)
        
        if provider == "anthropic":
            if not api_key:
                raise ValueError("Anthropic API key is required")
            return AnthropicClient(api_key, model, base_url)
        
        if provider == "google":
            if not api_key:
                raise ValueError("Google API key is required")
            return GoogleGeminiClient(api_key, model, base_url)
        
        # ÂÖ∂‰ªñÊâÄÊúâ OpenAI ÂÖºÂÆπÁöÑÊèê‰æõÂïÜ
        if provider in ["deepseek", "qwen", "glm", "moonshot", "ernie", "minimax", "doubao", "ollama"]:
            # Ollama ‰∏çÈúÄË¶ÅÁúüÂÆûÁöÑ API key
            if provider == "ollama":
                api_key = api_key or "ollama"
            elif not api_key:
                raise ValueError(f"{provider} API key is required")
            
            return OpenAICompatibleClient(api_key, model, base_url)
        
        raise ValueError(f"Unsupported AI provider: {provider}")
    
    @classmethod
    def get_provider_info(cls, provider: AIProviderType) -> Dict[str, Any]:
        """Get provider information including default model and base URL."""
        return {
            "provider": provider,
            "default_model": cls.DEFAULT_MODELS.get(provider),
            "default_base_url": cls.DEFAULT_BASE_URLS.get(provider)
        }
    
    @classmethod
    def list_providers(cls) -> List[Dict[str, Any]]:
        """List all supported providers with their default configurations."""
        return [
            {
                "id": "openai",
                "name": "OpenAI GPT",
                "default_model": cls.DEFAULT_MODELS["openai"],
                "requires_api_key": True
            },
            {
                "id": "anthropic",
                "name": "Anthropic Claude",
                "default_model": cls.DEFAULT_MODELS["anthropic"],
                "requires_api_key": True
            },
            {
                "id": "google",
                "name": "Google Gemini",
                "default_model": cls.DEFAULT_MODELS["google"],
                "requires_api_key": True
            },
            {
                "id": "deepseek",
                "name": "DeepSeek",
                "default_model": cls.DEFAULT_MODELS["deepseek"],
                "requires_api_key": True
            },
            {
                "id": "qwen",
                "name": "ÈòøÈáå‰∫ëÈÄö‰πâÂçÉÈóÆ",
                "default_model": cls.DEFAULT_MODELS["qwen"],
                "requires_api_key": True
            },
            {
                "id": "glm",
                "name": "Êô∫Ë∞±AI (GLM)",
                "default_model": cls.DEFAULT_MODELS["glm"],
                "requires_api_key": True
            },
            {
                "id": "moonshot",
                "name": "Êúà‰πãÊöóÈù¢ Kimi",
                "default_model": cls.DEFAULT_MODELS["moonshot"],
                "requires_api_key": True
            },
            {
                "id": "ernie",
                "name": "ÁôæÂ∫¶ÊñáÂøÉ‰∏ÄË®Ä",
                "default_model": cls.DEFAULT_MODELS["ernie"],
                "requires_api_key": True
            },
            {
                "id": "minimax",
                "name": "MiniMax",
                "default_model": cls.DEFAULT_MODELS["minimax"],
                "requires_api_key": True
            },
            {
                "id": "doubao",
                "name": "Â≠óËäÇË±ÜÂåÖ",
                "default_model": cls.DEFAULT_MODELS["doubao"],
                "requires_api_key": True
            },
            {
                "id": "ollama",
                "name": "Ollama",
                "default_model": cls.DEFAULT_MODELS["ollama"],
                "requires_api_key": False
            },
            {
                "id": "mock",
                "name": "Mock (ÊµãËØïÊ®°Âºè)",
                "default_model": "mock",
                "requires_api_key": False
            }
        ]

