"""AI-powered document segmentation and knowledge extraction service."""
import json
from typing import List, Dict, Any, Optional
from infra.config import settings
from infra.ai_providers import AIProviderFactory, BaseAIClient
from models.graph import TextChunk, Triplet


class AISegmenter:
    """AI-powered document analysis and knowledge extraction."""
    
    def __init__(self):
        """Initialize AI segmenter with configured AI provider."""
        self.provider = settings.ai_provider
        self.client: Optional[BaseAIClient] = None
        self.model = None
        
        try:
            # ä¼˜å…ˆä½¿ç”¨æ–°çš„é€šç”¨é…ç½®
            api_key = settings.ai_api_key
            model = settings.ai_model
            base_url = settings.ai_base_url
            
            # å‘åå…¼å®¹ï¼šå¦‚æœä½¿ç”¨æ—§çš„providerï¼Œå°è¯•ä½¿ç”¨æ—§é…ç½®
            if self.provider == "openai" and not api_key:
                api_key = settings.openai_api_key
                model = model or settings.openai_model
                base_url = base_url or settings.openai_base_url
            elif self.provider == "ollama" and not base_url:
                base_url = settings.ollama_base_url
                model = model or settings.ollama_model
            
            # Mock æ¨¡å¼ä¸éœ€è¦ API key
            if self.provider == "mock":
                api_key = api_key or "mock"
            
            # åˆ›å»ºAIå®¢æˆ·ç«¯
            self.client = AIProviderFactory.create_client(
                provider=self.provider,
                api_key=api_key,
                model=model,
                base_url=base_url
            )
            self.model = self.client.model
            
            # è·å–æä¾›å•†åç§°ç”¨äºæ˜¾ç¤º
            provider_info = AIProviderFactory.get_provider_info(self.provider)
            provider_name = provider_info.get("name", self.provider)
            print(f"âœ… AI Segmenter initialized with {provider_name} (model: {self.model})")
            
        except ValueError as e:
            raise ValueError(f"Failed to initialize AI segmenter: {str(e)}")
    
    def optimize_user_prompt(self, user_prompt: str) -> str:
        """
        ä¼˜åŒ–ç”¨æˆ·æä¾›çš„ Promptï¼Œä½¿å…¶æ›´é€‚åˆæ–‡æ¡£åˆ†æã€‚
        
        Args:
            user_prompt: ç”¨æˆ·åŸå§‹ Prompt
            
        Returns:
            ä¼˜åŒ–åçš„ Prompt
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†å·¥ç¨‹å¸ˆï¼Œæ“…é•¿ä¼˜åŒ–æ–‡æ¡£åˆ†ææç¤ºè¯ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ç†è§£ç”¨æˆ·çš„åˆ†ææ„å›¾å’Œå…³æ³¨ç‚¹
2. å°†ç”¨æˆ·çš„éœ€æ±‚è½¬æ¢ä¸ºæ¸…æ™°ã€ç»“æ„åŒ–çš„åˆ†ææŒ‡ä»¤
3. ç¡®ä¿ä¼˜åŒ–åçš„æç¤ºè¯èƒ½å¤Ÿå¼•å¯¼ AI æå–é«˜è´¨é‡çš„çŸ¥è¯†å›¾è°±

ä¼˜åŒ–åŸåˆ™ï¼š
- ä¿ç•™ç”¨æˆ·çš„æ ¸å¿ƒå…³æ³¨ç‚¹å’Œåˆ†æç›®æ ‡
- è¡¥å……å¿…è¦çš„ç»“æ„åŒ–è¦æ±‚ï¼ˆå¦‚æ¦‚å¿µã€å…³ç³»ã€å±æ€§ç­‰ï¼‰
- ä½¿æŒ‡ä»¤æ›´åŠ æ˜ç¡®å’Œå¯æ‰§è¡Œ
- é¿å…è¿‡åº¦å¤æ‚ï¼Œä¿æŒç®€æ´æœ‰åŠ›

è¯·ç›´æ¥è¿”å›ä¼˜åŒ–åçš„æç¤ºè¯ï¼Œä¸è¦æ·»åŠ é¢å¤–è¯´æ˜ã€‚"""

        try:
            response_text = self.client.chat_completion(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"è¯·ä¼˜åŒ–ä»¥ä¸‹ç”¨æˆ·æç¤ºè¯ï¼š\n\n{user_prompt}"}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            optimized = response_text.strip()
            print(f"\nğŸ”§ [Promptä¼˜åŒ–]")
            print(f"   åŸå§‹: {user_prompt[:100]}...")
            print(f"   ä¼˜åŒ–: {optimized[:100]}...")
            
            return optimized
            
        except Exception as e:
            print(f"âš ï¸  Promptä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹Prompt: {str(e)}")
            return user_prompt
    
    def analyze_document_structure(
        self, 
        chunks: List[TextChunk],
        user_prompt: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        åˆ†ææ–‡æ¡£æ•´ä½“ç»“æ„ï¼Œè¯†åˆ«ä¸»é¢˜ã€å…³é”®æ¦‚å¿µç­‰ã€‚
        
        Args:
            chunks: æ–‡æ¡£æ–‡æœ¬å—åˆ—è¡¨
            user_prompt: ç”¨æˆ·è‡ªå®šä¹‰åˆ†ææç¤ºï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ–‡æ¡£ç»“æ„åˆ†æç»“æœ
        """
        # å–å‰3ä¸ªchunkä½œä¸ºæ ·æœ¬
        sample_text = "\n\n".join([c.text for c in chunks[:3]])
        
        base_prompt = """åˆ†æè¿™æ®µæ–‡æ¡£å†…å®¹ï¼Œè¯†åˆ«å…¶æ ¸å¿ƒä¸»é¢˜ã€å…³é”®æ¦‚å¿µå’ŒçŸ¥è¯†é¢†åŸŸã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{
    "themes": ["ä¸»é¢˜1", "ä¸»é¢˜2", ...],  // æ–‡æ¡£çš„æ ¸å¿ƒä¸»é¢˜ï¼ˆ3-5ä¸ªï¼‰
    "domains": ["é¢†åŸŸ1", "é¢†åŸŸ2", ...],  // æ¶‰åŠçš„çŸ¥è¯†é¢†åŸŸ
    "key_concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2", ...],  // æœ€é‡è¦çš„æ¦‚å¿µï¼ˆ5-10ä¸ªï¼‰
    "document_type": "ç±»å‹",  // å¦‚ï¼šæŠ€æœ¯æ–‡æ¡£ã€å­¦æœ¯è®ºæ–‡ã€æ•™ç¨‹ç­‰
    "complexity": "éš¾åº¦"  // å¦‚ï¼šå…¥é—¨ã€ä¸­çº§ã€é«˜çº§
}"""

        # å¦‚æœæœ‰ç”¨æˆ·Promptï¼Œå°†å…¶èå…¥åˆ†ææŒ‡ä»¤
        if user_prompt:
            analysis_prompt = f"{base_prompt}\n\nç”¨æˆ·ç‰¹åˆ«å…³æ³¨ï¼š{user_prompt}"
        else:
            analysis_prompt = base_prompt
        
        try:
            # å¯¹äºéœ€è¦ JSON æ ¼å¼çš„è¯·æ±‚ï¼Œä½¿ç”¨ json_mode å‚æ•°
            response_text = self.client.chat_completion(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯çŸ¥è¯†å›¾è°±ä¸“å®¶ï¼Œæ“…é•¿åˆ†ææ–‡æ¡£ç»“æ„å’Œè¯†åˆ«æ ¸å¿ƒæ¦‚å¿µã€‚è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚"},
                    {"role": "user", "content": f"{analysis_prompt}\n\næ–‡æ¡£å†…å®¹ï¼š\n{sample_text}"}
                ],
                temperature=0.3,
                json_mode=True
            )
            
            result = json.loads(response_text)
            return result
            
        except Exception as e:
            print(f"âš ï¸  æ–‡æ¡£ç»“æ„åˆ†æå¤±è´¥: {str(e)}")
            return {
                "themes": [],
                "domains": [],
                "key_concepts": [],
                "document_type": "unknown",
                "complexity": "unknown"
            }
    
    def extract_rich_knowledge(
        self,
        chunk: TextChunk,
        document_context: Dict[str, Any],
        user_prompt: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ä»æ–‡æœ¬å—ä¸­æå–ä¸°å¯Œçš„çŸ¥è¯†å†…å®¹ï¼ŒåŒ…æ‹¬æ¦‚å¿µã€å…³ç³»ã€å±æ€§ç­‰ã€‚
        
        Args:
            chunk: æ–‡æœ¬å—
            document_context: æ–‡æ¡£æ•´ä½“ä¸Šä¸‹æ–‡ï¼ˆä¸»é¢˜ã€é¢†åŸŸç­‰ï¼‰
            user_prompt: ç”¨æˆ·è‡ªå®šä¹‰æç¤ºï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æå–çš„çŸ¥è¯†å†…å®¹
        """
        themes = ", ".join(document_context.get("themes", []))
        domains = ", ".join(document_context.get("domains", []))
        
        base_system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†å›¾è°±æ„å»ºä¸“å®¶ã€‚å½“å‰æ–‡æ¡£ä¸»é¢˜ï¼š{themes}ï¼Œæ¶‰åŠé¢†åŸŸï¼š{domains}ã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ·±åº¦åˆ†ææ–‡æœ¬ï¼Œæå–ç»“æ„åŒ–çŸ¥è¯†ï¼Œè€Œä¸ä»…ä»…æ˜¯æ ¼å¼è½¬æ¢ã€‚

è¯·æå–ï¼š
1. **æ ¸å¿ƒæ¦‚å¿µ**ï¼šè¯†åˆ«é‡è¦çš„å®ä½“ã€æœ¯è¯­ã€ç†è®ºç­‰
2. **æ¦‚å¿µå±æ€§**ï¼šæ¯ä¸ªæ¦‚å¿µçš„å®šä¹‰ã€ç‰¹å¾ã€åˆ†ç±»ç­‰
3. **æ¦‚å¿µå…³ç³»**ï¼šæ¦‚å¿µä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼ˆå› æœã€åŒ…å«ã€å¯¹æ¯”ç­‰ï¼‰
4. **éšå«çŸ¥è¯†**ï¼šæ–‡æœ¬æš—ç¤ºä½†æœªæ˜è¯´çš„çŸ¥è¯†

è¿”å›JSONæ ¼å¼ï¼š
{{
    "concepts": [
        {{
            "name": "æ¦‚å¿µåç§°",
            "description": "è¯¦ç»†æè¿°ï¼ˆç”¨ä½ çš„ç†è§£æ€»ç»“ï¼Œä¸æ˜¯ç…§æŠ„åŸæ–‡ï¼‰",
            "domain": "æ‰€å±é¢†åŸŸ",
            "category": "æ¦‚å¿µç±»å‹ï¼ˆå¦‚ï¼šç†è®º/æ–¹æ³•/å·¥å…·/äººç‰©/äº‹ä»¶ç­‰ï¼‰",
            "attributes": {{"å±æ€§å": "å±æ€§å€¼"}},
            "aliases": ["åˆ«å1", "åˆ«å2"],
            "importance": "high/medium/low"
        }}
    ],
    "triplets": [
        {{
            "subject": "ä¸»ä½“æ¦‚å¿µ",
            "predicate": "å…³ç³»ç±»å‹ï¼ˆç”¨è¯­ä¹‰åŒ–çš„åŠ¨è¯ï¼Œå¦‚ï¼šå¯¼è‡´/åŒ…å«/ä¼˜äº/ä¾èµ–ç­‰ï¼‰",
            "object": "å®¢ä½“æ¦‚å¿µ",
            "context": "å…³ç³»çš„ä¸Šä¸‹æ–‡è¯´æ˜"
        }}
    ],
    "insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2"]  // ä½ ä»æ–‡æœ¬ä¸­è·å¾—çš„æ·±å±‚ç†è§£
}}"""

        # èåˆç”¨æˆ·Prompt
        if user_prompt:
            system_prompt = f"{base_system_prompt}\n\nç”¨æˆ·ç‰¹åˆ«è¦æ±‚ï¼š{user_prompt}\nè¯·åœ¨åˆ†ææ—¶ç‰¹åˆ«å…³æ³¨ç”¨æˆ·çš„éœ€æ±‚ã€‚"
        else:
            system_prompt = base_system_prompt
        
        try:
            # å¯¹äºéœ€è¦ JSON æ ¼å¼çš„è¯·æ±‚ï¼Œä½¿ç”¨ json_mode å‚æ•°
            response_text = self.client.chat_completion(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"è¯·æ·±åº¦åˆ†æä»¥ä¸‹æ–‡æœ¬å¹¶æå–çŸ¥è¯†ï¼š\n\n{chunk.text}"}
                ],
                temperature=0.5,  # ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´æœ‰åˆ›é€ æ€§çš„æ´å¯Ÿ
                json_mode=True
            )
            
            result = json.loads(response_text)
            
            # è½¬æ¢ä¸ºå†…éƒ¨æ•°æ®ç»“æ„
            concepts = []
            for c in result.get("concepts", []):
                concepts.append({
                    "name": c.get("name", ""),
                    "description": c.get("description", ""),
                    "domain": c.get("domain", ""),
                    "category": c.get("category", ""),
                    "attributes": c.get("attributes", {}),
                    "aliases": c.get("aliases", []),
                    "importance": c.get("importance", "medium")
                })
            
            triplets = []
            for t in result.get("triplets", []):
                triplets.append(Triplet(
                    subject=t.get("subject", ""),
                    predicate=t.get("predicate", ""),
                    object=t.get("object", ""),
                    context=t.get("context", "")
                ))
            
            return {
                "concepts": concepts,
                "triplets": triplets,
                "insights": result.get("insights", [])
            }
            
        except Exception as e:
            print(f"âš ï¸  çŸ¥è¯†æå–å¤±è´¥: {str(e)}")
            return {
                "concepts": [],
                "triplets": [],
                "insights": []
            }

